{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import twitter_samples,stopwords\n",
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/harshkulkarni/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/harshkulkarni/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000   5000\n"
     ]
    }
   ],
   "source": [
    "print(len(all_positive_tweets), \" \", len(all_negative_tweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "x_test=all_positive_tweets[:4000]+all_negative_tweets[:4000]\n",
    "x_train=all_positive_tweets[4000:]+all_negative_tweets[4000:]\n",
    "y_train=np.append((np.ones((4000,1))),np.zeros((4000,1)))\n",
    "y_test=np.append((np.ones((1000,1))),np.zeros((1000,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    stemmer=PorterStemmer()\n",
    "    tockeniser=TweetTokenizer(preserve_case=False,reduce_len=True,strip_handles=True)\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    stop_words_eng=stopwords.words('english')\n",
    "    tockens=tockeniser.tokenize(tweet)\n",
    "    tweet_clean=[]\n",
    "    for tocken in tockens:\n",
    "        if(tocken not in stop_words_eng and tocken not in string.punctuation):\n",
    "            stemmer.stem(tocken)\n",
    "            tweet_clean.append(tocken)\n",
    "    return tweet_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulid_freq(tweets,target):\n",
    "    ys=np.squeeze(target).tolist()\n",
    "    freqs={}\n",
    "    for tweet,y in zip(tweets,ys):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair=(word,y)\n",
    "            if(pair in freqs):\n",
    "                freqs[pair]+=1\n",
    "            else:\n",
    "                freqs[pair]=1\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_freqs=bulid_freq(x_test,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(pair,freqs):\n",
    "    if(pair not in freqs):\n",
    "        return 0\n",
    "    else:\n",
    "        return freqs[pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(freqs):\n",
    "    vocab = set([pair[0] for pair in freqs.keys()])\n",
    "    V = len(vocab)\n",
    "    V_pos=0\n",
    "    V_neg=0\n",
    "    N_pos=0\n",
    "    N_neg=0\n",
    "    for pair in freqs.keys():\n",
    "        if pair[1]==1:\n",
    "            V_pos+=1\n",
    "            N_pos+=freqs[pair]\n",
    "        else:\n",
    "            V_neg+=1\n",
    "            N_neg+=freqs[pair]\n",
    "    loglikelihood={}\n",
    "    for word in vocab:\n",
    "        x1 = lookup((word,1),freqs)\n",
    "        x2=lookup((word,0),freqs)\n",
    "        pos=np.log((x1+1)/(N_pos+V_pos))\n",
    "        neg=np.log((x2+1)/(N_neg+V_neg))\n",
    "        loglikelihood[word]=pos-neg\n",
    "    logprior=np.log(len(all_positive_tweets)/len(x_train))-np.log(len(all_negative_tweets)/len(x_train))\n",
    "\n",
    "    return loglikelihood,logprior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglikelihood,logprior=Train(test_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_data):\n",
    "    y_predict=[]\n",
    "    print(len(test_data))\n",
    "    for tweet in test_data:\n",
    "        sum=0\n",
    "        for word in process_tweet(tweet):\n",
    "            if(word in loglikelihood):\n",
    "                sum+=loglikelihood[word]\n",
    "        sentiment=logprior+sum\n",
    "        if(sentiment >0):\n",
    "            y_predict.append(1)\n",
    "        else:\n",
    "            y_predict.append(0)\n",
    "    return y_predict \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_accuracy(predict_y, test_y):\n",
    "    sum = 0\n",
    "    for i in range(len(predict_y)):\n",
    "        sum += (predict_y[i] == test_y[i])\n",
    "    return (sum/len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict=test(x_train)\n",
    "len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_accuracy(y_predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tweet = ['I am happy because I am learning :)','I hate this']\n",
    "test(my_tweet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/harshkulkarni/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets=twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_positive_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)'"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_positive_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "x_train=all_positive_tweets[:4000]+all_negative_tweets[:4000]\n",
    "x_test=all_positive_tweets[4000:]+all_negative_tweets[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.append(np.ones((4000,1)),np.zeros((4000,1)),axis=0)\n",
    "y_test=np.append(np.ones((1000,1)),np.zeros((1000,1)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    stemmer=PorterStemmer()\n",
    "    tockeniser=TweetTokenizer(preserve_case=False,strip_handles=True,reduce_len=True)\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    #tockenising\n",
    "    tockens=tockeniser.tokenize(tweet)\n",
    "    stopwords_english=stopwords.words('english')\n",
    "    tweet_clean=[]\n",
    "    for word in tockens:\n",
    "        if(word not in stopwords_english and word not in string.punctuation):\n",
    "            #stemming\n",
    "            word=stemmer.stem(word)\n",
    "            tweet_clean.append(word)\n",
    "    return tweet_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Setniment Analysis\n",
    "def buid_freq(tweets,target):\n",
    "    freq={}\n",
    "    ys=np.squeeze(target).tolist()\n",
    "    for tweet,y in zip(tweets,ys):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair=(word,y)\n",
    "            if(pair in freq):\n",
    "                freq[pair]+=1\n",
    "            else:\n",
    "                freq[pair]=1\n",
    "    return freq;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs=buid_freq(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, frequencies):\n",
    "    words=process_tweet(tweet)\n",
    "    x = np.zeros((1, 3)) \n",
    "    x[0,0]=1\n",
    "    for word in words:\n",
    "        x[0][1]+=frequencies.get((word,1),0)\n",
    "        x[0][2]+=frequencies.get((word,0),0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed=np.zeros((len(x_train),3))\n",
    "for i in range(len(x_train)):\n",
    "    tweet=x_train[i]\n",
    "    features=extract_features(tweet,freqs)\n",
    "    pre_processed[i][0]=features[0][0]\n",
    "    pre_processed[i][1]=features[0][1]\n",
    "    pre_processed[i][2]=features[0][2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 3.020e+03, 6.100e+01],\n",
       "       [1.000e+00, 3.573e+03, 4.440e+02],\n",
       "       [1.000e+00, 3.005e+03, 1.150e+02],\n",
       "       ...,\n",
       "       [1.000e+00, 1.440e+02, 7.830e+02],\n",
       "       [1.000e+00, 2.050e+02, 3.890e+03],\n",
       "       [1.000e+00, 1.890e+02, 3.974e+03]])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshkulkarni/opt/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression(random_state=0).fit(pre_processed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.zeros((len(x_test),3))\n",
    "for i in range(len(x_test)):\n",
    "    tweet=x_test[i]\n",
    "    features=extract_features(tweet,freqs)\n",
    "    test[i][0]=features[0][0]\n",
    "    test[i][1]=features[0][1]\n",
    "    test[i][2]=features[0][2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.15"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score=accuracy_score(y_predict,y_test)\n",
    "acc_score*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[988,   5],\n",
       "       [ 12, 995]])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ridicul', 'bright', 'movi', 'plot', 'terribl', 'sad', 'end']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.,  38., 170.]])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##predicting sentiment of your won tweet \n",
    "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
    "my_freq={}\n",
    "print( process_tweet(my_tweet))\n",
    "\n",
    "for word in process_tweet(my_tweet):\n",
    "    pair=(word,0)\n",
    "    if(pair in my_freq):\n",
    "        my_freq[pair]+=1\n",
    "    else:\n",
    "        my_freq[pair]=1\n",
    "my_test=np.zeros((1,3))\n",
    "my_features=extract_features(my_tweet,freqs)\n",
    "my_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p = model.predict(my_features)\n",
    "y_p\n",
    "# acc_score = accuracy_score(y_predict, [0])\n",
    "# acc_scor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
